{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия\n",
    "$$a(x) = w_0 + w_1 x_1 + ... + w_d x_d$$\n",
    "- $w_0$ - свободный коэффициент, сдвиг, bias. Без свободного коэффициента модель гарантированно будет давать нулевой прогноз при нулевых значениях всех признаков, а это ограничивает возможности по подгонке под данные\n",
    "\n",
    "\n",
    "- $w_i$ - веса, коэффициенты, параметры модели\n",
    "- $d+1$ - количество параметров\n",
    "\n",
    "$$a(x) = w_0 + w_1 x_1 + ... + w_d x_d = w_0 + <w,x>$$\n",
    "\n",
    "Для удобства и возможности применять скалярное произведения добавим единичный признак:\n",
    "\n",
    "$$a(x) = w_0 * 1 + w_1 x_1 + ... + w_d x_d = <w,x>$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$a(x) = w_0 + w_1 (площадь \\_ квартиры) + w_2 (район) + w_3 (расстояние \\_ до \\_ метро)$$\n",
    "### Что делать, если признаки не числовые (район)?\n",
    "- район - категориальный признак, нужно закодировать.\n",
    "- one-hot кодирование, бинарное кодирование\n",
    "- Вместо одного категориального признака заведём много бинарных. Первый признак - это индикатор того, что исходный категориальный признак равен первой категории, второй признак - равенство второй категории. Это значит, что только один бинарный признак будет равен единице, остальные - нули. \n",
    "| Район | \n",
    "| --- | \n",
    "|Чкаловский|\n",
    "|Эльмаш|\n",
    "|Уралмаш|\n",
    "|Эльмаш|\n",
    "|Чкаловский|\n",
    "\n",
    "| Чкаловский | Эльмаш | Уралмаш |\n",
    "| --- | --- | --- |\n",
    "|1|0|0|\n",
    "|0|1|0|\n",
    "|0|0|1|\n",
    "|0|1|0|\n",
    "|1|0|0|\n",
    "\n",
    "\n",
    "$$a(x) = w_0 + w_1 (площадь) + w_2 (квартира \\ находится\\ в\\ Чкаловском\\ р-не?) + w_3 (квартира \\ находится\\ на\\ Эльмаше?) + w_4 (квартира \\ находится\\ на\\ Уралмаше?) $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что делать, если зависимость нелинейная (расстояние до метро)?\n",
    "<img src = 'images/underground.png'>\n",
    "Разобьем на линейные отрезки (новые признаки).\n",
    "Если расстояние до метро попало в интервал от $t_0$ до $t_1$, то признак равен 1. Остальные признаки попадания в интервал равны 0.\n",
    "\n",
    "$$a(x) = w_0 + w_1 *(площадь) + ... + w_3 * [t_0 <= x_3 < t_1] + ... + w_{3+n}[t_{n-1} <= x_3 < t_n]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель линейной регрессии применима, если трансформировать все признаки специально под неё, например, использовать one-hot кодирование категориальных признаков или бинаризацию числовых"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель линейной регрессии\n",
    "$$a(x) = <w, x>$$\n",
    "\n",
    "\n",
    "- Берём объект $x_i$, считаем прогноз модели $<w,x_i>$, вычитаем истинный ответ $y_i$, возводим в квадрат, усредняем по всей выборке. Нужно найти $w$, при котором ошибка будет как можно меньше. \n",
    "\n",
    "Перепишем задачу оптимизации в матричном виде:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Матрица объекты-признаки:__\n",
    "$$\\begin{pmatrix} x_{11} & x_{12} & \\dots & x_{1d} \\\\ x_{21} & x_{22} & \\dots & x_{2d} \\\\ \\dots & \\dots & \\dots & \\dots \\\\ x_{l1} & x_{l2} & \\dots & x_{ld} \\end{pmatrix}$$\n",
    "Каждая строка соответствует объекту, столбцы - признаки. \n",
    "\n",
    "$$\\begin{pmatrix} w_1 \\\\ w_2 \\\\ \\dots \\\\ w_d \\end{pmatrix}$$\n",
    "__Применение линейной модели:__\n",
    "$$a(x) = <w, x> = w_1 x_1 + \\dots + w_d x_d$$\n",
    "\n",
    "__Нужно получить вектор прогнозов на всей обучающей выборке:__\n",
    "$$\\begin{pmatrix} \\sum _{i=1} ^ d w_i x_{1i} \\\\ \\sum _{i=1} ^ d w_i x_{2i} \\\\ \\dots \\\\ \\sum _{i=1} ^ d w_i x_{li} \\end{pmatrix}$$\n",
    "Первая строка - сумма всех признаков первого объекта с весами.\n",
    "\n",
    "__Матричное умножение:__\n",
    "$$AB=C$$\n",
    "$$c_{ij} = \\sum_{p=1}^{k} a_{ip}b_{pj}$$\n",
    "_Скалярное умножение i-строки первой матрицы на j-столбец второй матрицы_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Результат применения линейной модели к выборке X:__\n",
    "$$Xw=\\begin{pmatrix} x_{11} & x_{12} & \\dots & x_{1d} \\\\ x_{21} & x_{22} & \\dots & x_{2d} \\\\ \\dots & \\dots & \\dots & \\dots \\\\ x_{l1} & x_{l2} & \\dots & x_{ld} \\end{pmatrix} * \\begin{pmatrix} w_1 \\\\ w_2 \\\\ \\dots \\\\ w_d \\end{pmatrix}=\\begin{pmatrix} \\sum _{i=1} ^ d w_i x_{1i} \\\\ \\sum _{i=1} ^ d w_i x_{2i} \\\\ \\dots \\\\ \\sum _{i=1} ^ d w_i x_{li} \\end{pmatrix}=\\begin{pmatrix} <w, x_1> \\\\ \\dots \\\\ <w,x_l>\\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Cреднеквадратическая ошибка:__\n",
    "$$\\displaystyle {\\frac{1}{l} \\sum _{i=1}^{l}{(<w,x_i> - y_i)^2 -> min_w}}$$\n",
    "__Отклонения прогнозов от ответов:__\n",
    "$$Xw-y=\\begin{pmatrix} <w, x_1> - y_1 \\\\ \\dots \\\\ <w,x_l> - y_l\\end{pmatrix}$$\n",
    "$Xw$ - прогнозы\n",
    "\n",
    "$y$ - истинные ответы\n",
    "__Средний квадрат отклонения:__\n",
    "Евклидова норма:\n",
    "$$||z|| = \\sqrt {\\sum _{j=1} ^ n z_{j}^2}$$\n",
    "Можно возвести в квадрат:\n",
    "$$||z||^2 = \\sum _{j=1} ^ n z_{j}^2$$\n",
    "\n",
    "__MSE в матричном виде:__\n",
    "$$\\displaystyle {\\frac{1}{l} ||Xw-y||^2 = \\frac{1}{l} \\sum _{i=1}^{l}{(<w,x_i> - y_i)^2 -> min_w}}$$\n",
    "\n",
    "_Умножаем матрицу объекты-признаки $X$ на $w$, вычитаем истинные ответы $y$, берем квадрат евклидовой нормы и делим на $l$_\n",
    "\n",
    "_В numpy: np.square(X.dot(w)-y).mean()_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение линейной регрессии\n",
    "Требуется найти $w$\n",
    "$$Q(w_1, \\dots, w_d)=\\sum _{i=1} ^{l} (w_1 x_1 + \\dots + w_d x_d -y_i)^2$$\n",
    "Производная:\n",
    "$$\\displaystyle{\\lim_{x \\to x_0} \\frac{f(x) - f(x_0)}{x - x_0} = f'(x_0)}$$\n",
    "<img src = 'images/derivative.png'>\n",
    "- Зафиксируем точку $x_0$\\\n",
    "- Возьмём точку $x$ рядом с $x_0$\n",
    "- Посчитаем знаменатель (разница между $x$ и $x_0$)\n",
    "- Посчитаем числитель (разница между значениями функции в этих точках)\n",
    "- Разделим\n",
    "\n",
    "\n",
    "Узнаем, насколько быстро функция растёт между этими двумя точками.\n",
    "Если приближать $x$ и $x_0$, то в пределе получим производную функции $f$ в точке $x_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
